include required(classpath("application"))

system {
  # Number of seconds between workflow launches
  new-workflow-poll-rate = 1

  io {
    # Throttle for GCS calls.
    number-of-requests = 10240611
  }
}

database {
  profile = "slick.jdbc.MySQLProfile$"
  db {
    driver = "com.mysql.cj.jdbc.Driver"
    url = "jdbc:mysql://db:3306/"${MYSQL_DATABASE}"?rewriteBatchedStatements=true"
    user = ${MYSQL_USER}
    password = ${MYSQL_PASSWORD}
    connectionTimeout = 20000
    numThreads = 100
    queueSize = 2000
  }

  migration {
    # For databases with a very large number of symbols, selecting all the rows at once can generate a variety of
    # problems. In order to avoid any issue, the selection is paginated. This value sets how many rows should be
    # retrieved and processed at a time, before asking for the next chunk.
    read-batch-size = 100000

    # Because a symbol row can contain any arbitrary wdl value, the amount of metadata rows to insert from a single
    # symbol row can vary from 1 to several thousands (or more). To keep the size of the insert batch from growing out
    # of control we monitor its size and execute/commit when it reaches or exceeds writeBatchSize.
    write-batch-size = 100000
  }
}

backend {
  default = "Local"

  providers {
    Local {
      config {
        root = "/executions"

        filesystems {
          gcs {
            auth = ${GOOGLE_AUTH_MODE}
          }
        }
      }
    }

    PAPIv2 {
      actor-factory = "cromwell.backend.google.pipelines.v2alpha1.PipelinesApiLifecycleActorFactory"
      config {
        # Google project
        project = ${GOOGLE_CLOUD_PROJECT}

        # Base bucket for workflow executions
        root = "gs://"${?GOOGLE_EXECUTIONS_BUCKET}"/workflows"

        # Used to help determine maximum throughput to the Google Genomics API. Setting this value too low will
        # cause a drop in performance. Setting this value too high will cause QPS based locks from Google.
        # 1000 is the default "Queries per 100 seconds per user", 50000 is the default "Queries per 100 seconds"
        # See https://cloud.google.com/genomics/quotas for more information
        #
        # Set this to the lower of the two values "Queries per 100 seconds" and "Queries per 100 seconds per user" for
        # your project.
        genomics-api-queries-per-100-seconds = 50000

        # Polling for completion backs-off gradually for slower-running jobs.
        # This is the maximum polling interval (in seconds):
        maximum-polling-interval = 100

        genomics {
          # A reference to an auth defined in the `google` stanza at the top.  This auth is used to create
          # Pipelines and manipulate auth JSONs.
          auth = ${GOOGLE_AUTH_MODE}

          # Endpoint for APIs, no reason to change this unless directed by Google.
          endpoint-url = "https://genomics.googleapis.com/"

          restrict-metadata-access = true
        }

        filesystems {
          gcs {
            # A reference to a potentially different auth for manipulating files via engine functions.
            auth = ${GOOGLE_AUTH_MODE}
            # caching {
            #   duplication-strategy = "reference"
            # }
          }
        }

        default-runtime-attributes {
          cpu: 1
          memory: "1G"
          disks: "local-disk 1 HDD"
          preemptible: 3
          maxRetries: 1
          zones: [
            "us-east1-b", "us-east1-c", "us-east1-d",
            "us-central1-a", "us-central1-b", "us-central1-c", "us-central1-f",
            "us-west1-a", "us-west1-b", "us-west1-c"
          ]
        }
      }
    }
  }
}

call-caching {
  enabled = true
}

google {
  # application-name = "cromwell"
  auths = [
    {
      name = "application-default"
      scheme = "application_default"
    },
    {
      name = "service-account"
      scheme = "service_account"
      json-file = ${GOOGLE_APPLICATION_CREDENTIALS}
    }
  ]
}
